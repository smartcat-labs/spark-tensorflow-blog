{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow + Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use Spark for tensorflow application. There is two segment of this notebook. First one is about data parallelization, when data can stack up on single machine. Second one is task parallelilzation of tensorflow accross claster, that can be used only if data can be stored on single machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataPoint = namedtuple('data_point', ['label','features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points = [DataPoint(1.0, [1.0, 2.0, 3.0]),\n",
    "          DataPoint(0.0, [1.0, 1.0, 1.0]),\n",
    "          DataPoint(1.0, [2.0, 2.0, 2.0]),\n",
    "          DataPoint(1.0, [3.0, 3.0, 3.0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = (sc.parallelize(points)).toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function <code>next_batch</code> will give one portion of data every time called. This is useful for batch training step in neural networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchHandler(object):\n",
    "    def __init__(self, df):\n",
    "        self._df = df\n",
    "    \n",
    "    def next_batch(self, ratio=0.5, seed=None):\n",
    "        if seed==None:\n",
    "            return df.randomSplit([ratio, 1-ratio])[0]\n",
    "        else:\n",
    "            return df.randomSplit([ratio, 1-ratio],seed)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handler = BatchHandler(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SampleModel\n",
    "Simple model for dot product in TensorFlow, this makes graph of operations that will be executed on CPU or GPU when session starts.\n",
    "## Train\n",
    "Function <code>train</code> is a sample function that takes <code>BatchHandler</code> and some model of tensorflow graph, for example it can be neural network model, but in this case it's <code>SampleModel</code> of dot product. Performance issue - using <code>collect()</code>\n",
    "## Task\n",
    "Function <code>taks</code> like function <code>train</code> performe simple dot product of TensorFlow, but there is no dataframe and this function assumes that whole data can be stored in memory of single machine. Thus, this function can be executed in parallel with others <code>task</code> functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SampleModel(object):\n",
    "    \n",
    "    def __init__(self, parameter):\n",
    "        self.parameter = parameter\n",
    "        self.x = tf.constant(value=parameter)\n",
    "        self.y = tf.placeholder(dtype=tf.float32, shape=[3,])\n",
    "        \n",
    "        self.dot = tf.reduce_sum(tf.mul(self.x, self.y))\n",
    "\n",
    "def train(handler, sample_model):\n",
    "    batch = handler.next_batch().collect()  \n",
    "    \n",
    "    print 'BATCH:',batch,'SAMPLE_MODEL',sample_model.parameter\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    with tf.Session(config=config) as sess:\n",
    "        result = [sess.run(sample_model.dot, feed_dict = {sample_model.y:map(float,i['features'])}) for i in batch]\n",
    "    \n",
    "    \n",
    "    return result\n",
    "\n",
    "def task(dataset, sample_model):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    with tf.Session(config=config) as sess:\n",
    "        result = [sess.run(sample_model.dot, feed_dict = {sample_model.y:map(float,i)}) for i in dataset]\n",
    "    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [SampleModel([1.0, 1.0, 1.0]), SampleModel([2.0, 2.0, 2.0]), SampleModel([3.0, 3.0, 3.0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starts executing dot product with DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: [Row(label=1.0, features=[1.0, 2.0, 3.0]), Row(label=1.0, features=[3.0, 3.0, 3.0])] SAMPLE_MODEL [1.0, 1.0, 1.0]\n",
      "BATCH: [Row(label=1.0, features=[1.0, 2.0, 3.0]), Row(label=0.0, features=[1.0, 1.0, 1.0]), Row(label=1.0, features=[2.0, 2.0, 2.0]), Row(label=1.0, features=[3.0, 3.0, 3.0])] SAMPLE_MODEL [2.0, 2.0, 2.0]\n",
      "BATCH: [] SAMPLE_MODEL [3.0, 3.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "results = map(lambda x: train(handler,x), models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.0, 9.0], [12.0, 6.0, 12.0, 18.0], []]\n"
     ]
    }
   ],
   "source": [
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = [[1.0, 1.0, 1.0], [2.0, 2.0, 2.0], [3.0, 3.0, 4.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = [[1.0, 1.0, 1.0], [2.0, 2.0, 2.0], [3.0, 3.0, 4.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starts executing dot product of various models in parallel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task_results = sc.parallelize(parameters).map(lambda x: task(dataset, SampleModel(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[17] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3.0, 6.0, 10.0], [6.0, 12.0, 20.0], [10.0, 20.0, 34.0]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_results.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
